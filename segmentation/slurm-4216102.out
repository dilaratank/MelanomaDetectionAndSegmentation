Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################


This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 49, 'patch_size': [256, 256], 'median_image_size_in_voxels': [256.0, 256.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset011_Melanoma', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [3, 256, 256], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 155.04945373535156, 'median': 158.0, 'min': 0.0, 'percentile_00_5': 10.0, 'percentile_99_5': 253.0, 'std': 47.13301086425781}}} 

2023-10-19 16:08:27.553144: unpacking dataset...
2023-10-19 16:09:12.628128: unpacking done...
2023-10-19 16:09:12.631712: do_dummy_2d_data_aug: False
2023-10-19 16:09:12.642584: Using splits from existing split file: /home/scur0404/projects/MelanomaDetectionAndSegmentation/nnUNet_preprocessed/Dataset011_Melanoma/splits_final.json
2023-10-19 16:09:12.645189: The split file contains 5 splits.
2023-10-19 16:09:12.645279: Desired fold for training: 0
2023-10-19 16:09:12.645331: This split has 1331 training and 333 validation cases.
2023-10-19 16:09:12.702962: Unable to plot network architecture:
2023-10-19 16:09:12.703048: No module named 'IPython'
2023-10-19 16:09:12.732475: 
2023-10-19 16:09:12.732574: Epoch 0
2023-10-19 16:09:12.732703: Current learning rate: 0.01
using pin_memory on device 0
using pin_memory on device 0
2023-10-19 16:09:54.142533: train_loss 0.2006
2023-10-19 16:09:54.142754: val_loss -0.126
2023-10-19 16:09:54.142843: Pseudo dice [0.5991]
2023-10-19 16:09:54.142938: Epoch time: 41.41 s
2023-10-19 16:09:54.143018: Yayy! New best EMA pseudo Dice: 0.5991
Traceback (most recent call last):
  File "/home/scur0404/.local/lib/python3.10/site-packages/torch/serialization.py", line 441, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol)
  File "/home/scur0404/.local/lib/python3.10/site-packages/torch/serialization.py", line 668, in _save
    zip_file.write_record(name, storage.data_ptr(), num_bytes)
RuntimeError: [enforce fail at inline_container.cc:471] . PytorchStreamWriter failed writing file data/40: file write failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
: 
)

, , , )